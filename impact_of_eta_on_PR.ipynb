{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prejudice Remover to Test Impact of Eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals:**\n",
    "* Which samples get different predictions under different classifiers? \n",
    "\n",
    "* Which samples get different decisions (difficult decisions/samples).\n",
    "\n",
    "* How much change induced onto eta will make the classifier produce different decisions?\n",
    "\n",
    "* Create plot of changing eta over sample classification.\n",
    "\n",
    "**Output:**\n",
    "* Output CSV for test set for PrejudiceRemover, for each eta add a column of predictions for each different value of eta for that sample.\n",
    "\n",
    "* Ability to pick 2 features, scattered the samples of that feature, and ability to move the slider (eta) with samples changing real-time.\n",
    "\n",
    "**Notes:**\n",
    "* Eta is 1 - fairness and accuracy are equal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will set up a prejudice_remover algorithm in order to make sure I understand the process of how it works, and if I can set it up correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_compas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aif360.metrics import BinaryLabelDatasetMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and train, label as necessary\n",
    "data = load_preproc_data_compas()\n",
    "# For protected attribute sex, Female is privileged, and Male is unprivileged\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "# Split at 70/30\n",
    "data_train, data_test = data.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3694, 10)\n",
      "0.0 1.0\n",
      "['sex', 'race']\n",
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n",
      "['sex', 'race', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'priors_count=0', 'priors_count=1 to 3', 'priors_count=More than 3', 'c_charge_degree=F', 'c_charge_degree=M']\n"
     ]
    }
   ],
   "source": [
    "# Looking at our dataset\n",
    "# Shape of data\n",
    "print(data_train.features.shape)\n",
    "# Labels of data\n",
    "print(data_train.favorable_label, data_train.unfavorable_label)\n",
    "# Attribute names (protected)\n",
    "print(data_train.protected_attribute_names)\n",
    "# Attribute values (protected)\n",
    "print(data_train.privileged_protected_attributes, \n",
    "      data_train.unprivileged_protected_attributes)\n",
    "# Feature names\n",
    "print(data_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting original data for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original training data\n",
    "metric_orig_train = BinaryLabelDatasetMetric(data_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original testing data\n",
    "metric_orig_test = BinaryLabelDatasetMetric(data_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression classifier and predictions for training data\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(data_train.features)\n",
    "y_train = data_train.labels.ravel()\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the prejudice remover model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.prejudice_remover.PrejudiceRemover at 0x2923d573e20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using prejudice remover\n",
    "pr = PrejudiceRemover(eta=1.0, sensitive_attr='sex')\n",
    "pr.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = pr.predict(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
